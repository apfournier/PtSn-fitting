{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import listdir, mkdir, path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import medfilt\n",
    "import re\n",
    "from sklearn import tree\n",
    "%matplotlib\n",
    "#import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder1 = '/Users/Amanda/Desktop/PtSn/PtSn1/'\n",
    "folder2 = '/Users/Amanda/Desktop/PtSn/PtSn2/'\n",
    "bgfile1 = '/Users/Amanda/Desktop/PtSn/PtSn1/PtSn1-background.dat'\n",
    "bgfile2 = '/Users/Amanda/Desktop/PtSn/PtSn2/PtSn2--background.dat'\n",
    "loc1 = path.join(folder1, 'addtnl', 'PtSn1')\n",
    "loc2 = path.join(folder2, 'addtnl', 'PtSn2')\n",
    "\n",
    "sequencestarters1 = ['/Users/Amanda/Desktop/PtSn/PtSn1/PtSn1_scan1_0000_C.dat',\n",
    "                    '/Users/Amanda/Desktop/PtSn/PtSn1/PtSn1_1_scan1_0000_C.dat',\n",
    "                    '/Users/Amanda/Desktop/PtSn/PtSn1/PtSn1_2_scan1_0000_C.dat']\n",
    "sequencestarters2 = ['/Users/Amanda/Desktop/PtSn/PtSn2/_PtSn2_scan1_0000_C.dat',\n",
    "                     '/Users/Amanda/Desktop/PtSn/PtSn2/PtSn2_1_scan1_0000_C.dat',\n",
    "                     '/Users/Amanda/Desktop/PtSn/PtSn2/PtSn2_2_scan1_0000_C.dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I1,q1,sigma1,I2,sigma2\n",
    "fcc_bcc_bounds1_I = ([0,2.69,0.025, 0,0.025, 0,2.80,0.025, 0,0.025],\n",
    "                     [4,2.79,0.08,  4,0.08,  4,2.9,0.08,   4,0.08])\n",
    "fcc_bcc_initialvalues1_I = [[1.29, 2.74,0.05, 0.225,0.05,  0.125,2.85,0.05, 0.125,0.05],\n",
    "                            [0.125,2.74,0.05, 0.125,0.05,  0.636,2.85,0.05, 0.300,0.05],\n",
    "                            [0.087,2.74,0.05, 0.037,0.05,  0.708,2.85,0.05, 0.401,0.05]]\n",
    "fcc_bcc_bounds2_I = ([0,2.69,0.025, 0,0.025, 0,2.80,0.025, 0,0.025],\n",
    "                     [4,2.79,0.08,  4,0.08,  4,3.06,0.08,   4,0.08])\n",
    "fcc_bcc_initialvalues2_I = [[1.027,2.74,0.05, 0.125,0.05, 0.125,3.01,0.05, 0.250,0.05],\n",
    "                            [0.689,2.74,0.05, 0.062,0.05, 0.062,3.01,0.05, 0.137,0.05],\n",
    "                            [0.714,2.74,0.05, 0.062,0.05, 0.062,3.01,0.05, 0.162,0.05]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigma2ratio measured on high-SNR plots represents a lower extremeness limit for the physical ratio, which can always be pushed towards 1:1 by lower instrumental resolution.  It seems unlikely for this low-SNR data to have better spatial resolution than the exemplar hiSNR spectra.\n",
    "\n",
    "Integrated intensity is a truly physical parameter, not dependent on instrumentation. Not sure how much it should vary with composition; tried to set reasonable boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I1,q1,sigma1,I2ratio,sigma2ratio\n",
    "bounds1 = ([0,2.69,0.025, 0.2,0.8, 0,2.80,0.025, 0,0.025],\n",
    "           [4,2.79,0.08,  0.5,1.1, 4,2.9,0.08,   4,0.08])\n",
    "initialvalues1 = [[1.29, 2.74,0.05, 0.2,0.94,  0.125,2.85,0.05, 0.125,0.05],\n",
    "                  [0.125,2.74,0.05, 0.5,0.94,  0.636,2.85,0.05, 0.300,0.05],\n",
    "                  [0.087,2.74,0.05, 0.5,0.94,  0.708,2.85,0.05, 0.401,0.05]]\n",
    "# I1,q1,sigma1,I2,sigma2\n",
    "bounds2 = ([0,2.69,0.025, 0.2,0.8, 0,2.80,0.025, 0,0.025],\n",
    "           [4,2.79,0.08,  0.5,1.1, 4,3.06,0.08,  4,0.08])\n",
    "initialvalues2 = [[1.027,2.74,0.05, 0.370,0.939, 0.125,3.01,0.05, 0.250,0.05],\n",
    "                  [0.689,2.74,0.05, 0.350,0.937, 0.062,3.01,0.05, 0.137,0.05],\n",
    "                  [0.714,2.74,0.05, 0.320,0.935, 0.062,3.01,0.05, 0.162,0.05]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for reading in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_subfolders(folder):\n",
    "    if not path.isdir(path.join(folder, 'addtnl')):\n",
    "        mkdir(path.join(folder, 'addtnl'))\n",
    "    if not path.isdir(path.join(folder, 'pdf')):\n",
    "        mkdir(path.join(folder, 'pdf'))\n",
    "    if not path.isdir(path.join(folder, 'png')):\n",
    "        mkdir(path.join(folder, 'png'))\n",
    "\n",
    "def find_n_order_files_PtSn(folder):\n",
    "    files = listdir(folder)\n",
    "    files2 = [ii for ii in files if ((not ii.__contains__('background')) & (not ii.__contains__('seeds')) & (not ii.__contains__('pdf')))]\n",
    "    seq1 = [ii for ii in files2 if re.match('[_]*PtSn[12]_scan1.*', ii)]\n",
    "    seq2 = [ii for ii in files2 if re.match('PtSn[12]_1_scan1.*', ii)]\n",
    "    seq3 = [ii for ii in files2 if re.match('PtSn[12]_2_scan1.*', ii)]\n",
    "    seq = seq1\n",
    "    seq.extend(seq2)\n",
    "    seq.extend(seq3)\n",
    "    files3 = [path.join(folder,  ii) for ii in seq]\n",
    "    return files3\n",
    "\n",
    "def readfiles(folder, bgfile, prefix):\n",
    "    mk_subfolders(folder)\n",
    "    bg = np.loadtxt(bgfile, skiprows=40)\n",
    "    bg_q, bg_I, _,_ = bg.T\n",
    "    filenames = find_n_order_files_PtSn(folder)\n",
    "    nfiles = len(filenames)\n",
    "    intensity_image = np.zeros((bg_q.size,nfiles),dtype=float)\n",
    "    error_image = np.zeros((bg_q.size,nfiles),dtype=float)\n",
    "    for ii in range(nfiles):\n",
    "        spectrum = np.loadtxt(filenames[ii], skiprows=34)\n",
    "        spec_q, spec_I, spec_dI, _ = spectrum.T\n",
    "        if (spec_q != bg_q).any():\n",
    "            raise ValueError(\"Issue!  domain mismatch %s\" % filenames[ii])\n",
    "        intensity_image[:,ii] = spec_I\n",
    "        error_image[:,ii] = spec_dI\n",
    "    #waterfall_plot(diff_image, bg, loc)\n",
    "    return intensity_image, error_image, bg, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intensity_image1, error_image1, bg1, files1 = readfiles(folder1, bgfile1, 'PtSn1')\n",
    "intensity_image2, error_image2, bg2, files2 = readfiles(folder2, bgfile2, 'PtSn2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for individual fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def gauss_a(x, a, x0, sigma):\n",
    "#    return a * np.exp(-0.5*((x - x0)/sigma)**2)\n",
    "\n",
    "def gauss(x, I, x0, sigma):\n",
    "    return I * (2*np.pi*sigma**2)**-0.5 * np.exp(-0.5*((x - x0)/sigma)**2)\n",
    "\n",
    "def manypeaks(x, *params):\n",
    "    # params pattern:  a0, x0, s0, a1, x1, s1...\n",
    "    params = np.array(params)\n",
    "    npeaks = params.size/3\n",
    "    y = np.zeros(x.shape,dtype=float)\n",
    "    for ii in range(npeaks):\n",
    "        Ii,xi,si = params[3*ii:3*ii+3]\n",
    "        y += gauss(x,Ii,xi,si)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "def fcc2(qq, I1, x1, s1, I2ratio, s2ratio):\n",
    "    # Suitable for pure Pt, Pt3Sn\n",
    "    return manypeaks(qq, I1, x1, s1, I1*I2ratio, x1*((4./3)**0.5), s1*s2ratio)\n",
    "\n",
    "def bcc2(qq, I1, x1, s1, I2, s2):\n",
    "    # Suitable for PtSn\n",
    "    return manypeaks(qq, I1, x1, s1, I2, x1*(0.9495**-1), s2)\n",
    "\n",
    "def mix_fcc2_bcc2(qq,*pars):\n",
    "    pars = list(pars)\n",
    "    fccpars = pars[:5]\n",
    "    bccpars = pars[5:]\n",
    "    return fcc2(qq,*fccpars) + bcc2(qq,*bccpars)\n",
    "\n",
    "def plot_one_guess(spec_q, diff, guess, loc, file, nn):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(spec_q, diff, c='k', lw=1)\n",
    "    ax.plot(spec_q, guess, c='k', lw=1.5)\n",
    "    ax.set_title('%s guess' % path.split(file)[1])\n",
    "    fig.savefig(loc + '_%i_guess.pdf' % nn)\n",
    "    plt.close(fig)\n",
    "    \n",
    "def waterfall_plot(diff_image, bg, loc):\n",
    "    nq,nfiles = diff_image.shape\n",
    "    qq,_,_,_ = bg.T\n",
    "    viridis = plt.get_cmap('viridis')\n",
    "    cNorm = colors.Normalize(vmin=0, vmax=nfiles)\n",
    "    scalarMap = cm.ScalarMappable(norm=cNorm, cmap=viridis)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([qq[0],qq[-1]], [0,0], color='k',lw=1.5)\n",
    "    for ii in range(nfiles):\n",
    "        colorVal = scalarMap.to_rgba(ii)\n",
    "        ax.plot(qq, diff_image[:,ii], color=colorVal, lw=0.5)\n",
    "    features = initial_features(bg)\n",
    "    ax.plot(qq[~features],-np.ones((~features).sum()),ls='none',marker=',',c='r')\n",
    "    ax.set_title('Waterfall; background regions')\n",
    "    fig.savefig(loc + '_waterfall.pdf')\n",
    "    #plt.close(fig)\n",
    "\n",
    "def initial_features(bg):\n",
    "    qq,_,_,_ = bg.T\n",
    "    features = ~(((qq > 3.5) & (qq < 4.3)) | ((qq > 2.2) & (qq < 2.5)) | (qq > 4.5))\n",
    "    return features\n",
    "    \n",
    "def array_plot(outputs, loc, bound_index_1, bound_index_2, nfiles):\n",
    "    npars,nfiles=outputs.shape\n",
    "    if npars==10:\n",
    "        fig, ax = plt.subplots(3,4)\n",
    "    if npars==5:\n",
    "        fig, ax = plt.subplots(3,2)\n",
    "    ax[0,0].plot(np.arange(nfiles), outputs[0,:])\n",
    "    ax[1,0].plot(np.arange(nfiles), outputs[1,:])\n",
    "    ax[2,0].plot(np.arange(nfiles), outputs[2,:])\n",
    "    ax[0,1].plot(np.arange(nfiles), outputs[0,:]*outputs[3,:])\n",
    "    ax[1,1].plot(np.arange(nfiles), outputs[1,:]*((4./3)**0.5))\n",
    "    ax[2,1].plot(np.arange(nfiles), outputs[2,:]*outputs[4,:])\n",
    "    if npars==10:\n",
    "        ax[0,2].plot(np.arange(nfiles), outputs[5,:])\n",
    "        ax[1,2].plot(np.arange(nfiles), outputs[6,:])\n",
    "        ax[2,2].plot(np.arange(nfiles), outputs[7,:])\n",
    "        ax[0,3].plot(np.arange(nfiles), outputs[8,:])\n",
    "        ax[1,3].plot(np.arange(nfiles), outputs[6,:]*(0.9495**-1))\n",
    "        ax[2,3].plot(np.arange(nfiles), outputs[9,:])\n",
    "    for ii in range(12):\n",
    "        axii = ax.flatten()[ii]\n",
    "        lims = axii.axis()\n",
    "        axii.plot([bound_index_1, bound_index_1], [lims[2]*1.001, lims[3]*0.999], c='r', ls='--')\n",
    "        axii.plot([bound_index_2, bound_index_2], [lims[2]*1.001, lims[3]*0.999], c='r', ls='--')\n",
    "    fig.suptitle('Parameter evolution')\n",
    "    ax[2,1].set_xlabel('Index')\n",
    "    ax[0, 0].set_ylabel('Integrated intensity')\n",
    "    ax[1, 0].set_ylabel('$q$ centroid')\n",
    "    ax[2, 0].set_ylabel('$q$ width ($\\sigma$)')\n",
    "    ax[0, 0].set_title('fcc peak 1')\n",
    "    ax[0, 1].set_title('fcc peak 2')\n",
    "    ax[0, 2].set_title('bcc peak 1')\n",
    "    ax[0, 3].set_title('bcc peak 2')\n",
    "    fig.savefig(loc + '_evolution_a.pdf')\n",
    "    #plt.close(fig)\n",
    "\n",
    "    \n",
    "    \n",
    "def bg_subtract_fit_individual(function, intensity_image, filenames, folder, bg, prefix, sequencestarters, initialvalues, bounds, demonstrative=False):\n",
    "    loc = path.join(folder, 'addtnl', prefix)\n",
    "    bg_q, bg_I, _,_ = bg.T\n",
    "    nfiles = len(filenames)\n",
    "    features = initial_features(bg)\n",
    "    nofit = np.zeros(nfiles,dtype=bool)\n",
    "    loc = path.join(folder, 'addtnl', prefix)\n",
    "    p0 = initialvalues[0]\n",
    "    outputs = np.zeros((len(initialvalues[0]),nfiles),dtype=float)\n",
    "    diff_image = np.zeros((bg_q.size,nfiles),dtype=float)\n",
    "    for ii in range(nfiles):\n",
    "        spec_I = intensity_image[:,ii]\n",
    "        mult = ((spec_I/bg_I)[~features]).mean()\n",
    "        diff = spec_I - mult*bg_I\n",
    "        diff_image[:,ii] = diff\n",
    "        if filenames[ii] in sequencestarters:\n",
    "            nn = sequencestarters.index(filenames[ii])\n",
    "            guess = function(bg_q, *initialvalues[nn])\n",
    "            plot_one_guess(bg_q, diff, guess, loc, filenames[ii], nn)\n",
    "        try:\n",
    "            popt, pcov = curve_fit(function, bg_q, diff, p0=p0, bounds=bounds)\n",
    "        except RuntimeError:\n",
    "            print '''Issue!  fitting failure %s''' % filenames[ii]\n",
    "            nofit[ii] = True\n",
    "            if np.isnan(diff).any():\n",
    "                print '''There are NaNs in this file's data.'''\n",
    "            if (diff == 0).any():\n",
    "                print '''There are zero-valued entries in this file's data.'''\n",
    "            figz, axz = plt.subplots()\n",
    "            axz.plot(bg_q, diff)\n",
    "            axz.plot(bg_q, function(bg_q, *p0), c='k', lw=1)\n",
    "            axz.set_title('This spectrum has fitting issues')\n",
    "        except ValueError:\n",
    "            import pdb; pdb.set_trace()\n",
    "        p0 = popt\n",
    "        outputs[:,ii] = popt\n",
    "        if demonstrative:\n",
    "            plot_one_fit(bg_q, diff, function(bg_q, *p0), folder, filenames[ii])\n",
    "    #\n",
    "    waterfall_plot(diff_image, bg, loc)\n",
    "    bound_index_1 = filenames.index(sequencestarters[1])\n",
    "    bound_index_2 = filenames.index(sequencestarters[2])\n",
    "    #array_plot_3(outputs, loc, bound_index_1, bound_index_2, nfiles)\n",
    "    array_plot(outputs, loc, bound_index_1, bound_index_2, nfiles)\n",
    "    '''\n",
    "    fname = path.join(folder, 'addtnl', prefix) + '_evolution.csv'\n",
    "    headertxt = 'index, peak height 1, q centroid 1, sigma width 1, integrated intensity 1, FWHM 1, '\\\n",
    "                + 'peak height 2, q centroid 2, sigma width 2, integrated intensity 2, FWHM 2, '\\\n",
    "                + 'peak height 3, q centroid 3, sigma width 3, integrated intensity 3, FWHM 3, '\\\n",
    "                + 'peak height 4, q centroid 4, sigma width 4, integrated intensity 4, FWHM 4'\n",
    "    np.savetxt(fname, outdata.T, fmt='%.18f', delimiter=',', newline='\\n', header=headertxt)\n",
    "    '''\n",
    "    #\n",
    "    fig6, ax6 = plt.subplots()\n",
    "    ax6.imshow(diff_image.T)\n",
    "    ax6.set_xlabel('q index')\n",
    "    ax6.set_ylabel('t index')\n",
    "    ax6.set_title('Background subtracted spectrum evolution')\n",
    "    fname = (path.join(folder, 'addtnl', prefix) + '_diffimage.pdf')\n",
    "    fig6.savefig(fname)\n",
    "    plt.close(fig6)\n",
    "    #\n",
    "    return outputs, intensity_image, diff_image, nofit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue!  fitting failure /Users/Amanda/Desktop/PtSn/PtSn2/_PtSn2_scan1_0037_C.dat\n"
     ]
    }
   ],
   "source": [
    "outputs1, intensity_image1, diff_image1, nofit1 = bg_subtract_fit_individual(mix_fcc2_bcc2,intensity_image1, files1, folder1, bg1, 'PtSn1', sequencestarters1, initialvalues1, bounds1)\n",
    "outputs2, intensity_image2, diff_image2, nofit2 = bg_subtract_fit_individual(mix_fcc2_bcc2,intensity_image2, files2, folder2, bg2, 'PtSn2', sequencestarters2, initialvalues2, bounds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast records of low-constraint fits for Liheng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bg_q1, _,_,_ = bg1.T\n",
    "fit_image1 = np.zeros(intensity_image1.shape, dtype=float)\n",
    "for ii in range(intensity_image1.shape[1]):\n",
    "    fit_image1[:,ii] = manypeaks(bg_q1, *outputs1[:,ii])\n",
    "#bg_q2, _,_,_ = bg2.T\n",
    "#fit_image2 = np.zeros(intensity_image2.shape, dtype=float)\n",
    "#for ii in range(intensity_image2.shape[1]):\n",
    "#    fit_image2[:,ii] = manypeaks(bg_q2, *outputs2[:,ii])\n",
    "#fname = path.join(folder, 'addtnl', prefix) + '_evolution.csv'\n",
    "headertxt = 'integrated intensity 1, q centroid 1, sigma width 1, '\\\n",
    "            + 'integrated intensity 2, q centroid 2, sigma width 2, '\\\n",
    "            + 'integrated intensity 3, q centroid 3, sigma width 3, '\\\n",
    "            + 'integrated intensity 4, q centroid 4, sigma width 4'\n",
    "np.savetxt(fname, outputs.T, fmt='%.18f', delimiter=',', newline='\\n', header=headertxt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for context-aware background subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def local_error_estimate(image):\n",
    "    error_estimate = np.zeros(image.shape, dtype=float)\n",
    "    error_estimate[1:-1,1:-1] = (image[1:-1,1:-1] - image[1:-1,2:])**2 \\\n",
    "                                + (image[1:-1,1:-1] - image[1:-1,:-2])**2 \\\n",
    "                                + (image[1:-1,1:-1] - image[2:,1:-1])**2 \\\n",
    "                                + (image[1:-1,1:-1] - image[:-2,1:-1])**2\n",
    "    error_estimate[0,:] = error_estimate[1,:]\n",
    "    error_estimate[-1,:] = error_estimate[-2,:]\n",
    "    error_estimate[:,0] = error_estimate[:,1]\n",
    "    error_estimate[:,-1] = error_estimate[:,-2]\n",
    "    error_estimate = (error_estimate / 8.) ** 0.5\n",
    "    return error_estimate\n",
    "\n",
    "def grow(arr, nn):\n",
    "    arr = arr.astype('bool')\n",
    "    for ii in range(nn):\n",
    "        arr[1:,:] = arr[1:,:] | arr[:-1,:]\n",
    "        arr[:-1,:] = arr[1:,:] | arr[:-1,:]\n",
    "        arr[:,1:] = arr[:,1:] | arr[:,:-1]\n",
    "        arr[:,:-1] = arr[:,1:] | arr[:,:-1]\n",
    "    return arr\n",
    "\n",
    "def twodeebg(intensity, bg_I, legit):\n",
    "    nq, nfiles = intensity.shape\n",
    "    blank = np.ones((nq, nfiles))\n",
    "    mult = np.ones(nfiles) #*blank\n",
    "    if len(bg_I.shape) == 1:\n",
    "        bg_I = bg_I.reshape((nq,1))*blank\n",
    "    mult[legit.any(axis=0)] = ((intensity / bg_I * legit).sum(axis=0)/legit.sum(axis=0,dtype=float)).reshape((nfiles,))[legit.any(axis=0)]  # potential problem line\n",
    "    if np.any(~legit.any(axis=0)):\n",
    "        print \"Some spectra/timeframes are entirely deselected.  Consider re-tuning your cutoff values.\"\n",
    "    mult = mult.reshape((1,nfiles))\n",
    "    #diff = intensity - mult*bg_I\n",
    "    diff = intensity/mult - bg_I\n",
    "    return mult, diff\n",
    "\n",
    "def plotarray(nplots, arrange_vertical=True):\n",
    "    nplots = int(nplots)\n",
    "    if arrange_vertical:\n",
    "        nrows = int(np.ceil(nplots**0.5))\n",
    "        ncols = int(np.ceil(nplots/nrows))\n",
    "    else:\n",
    "        ncols = int(np.ceil(nplots**0.5))\n",
    "        nrows = int(np.ceil(nplots/ncols))\n",
    "    fig, ax = plt.subplots(nrows,ncols)\n",
    "    flatax = ax.ravel()\n",
    "    for ii in range(ax.size):\n",
    "        if ii > (nplots - 1):\n",
    "            flatax[ii].axis('off')\n",
    "    return fig, ax\n",
    "\n",
    "def tree_bg(intensity_image, diff_image, bg, cutoff, tree_depth, max_iter=15, demonstrative=False, loc=None):\n",
    "    '''\"Demonstrative\" is like \"verbose\", but with plots instead of words.'''\n",
    "    nq, nfiles = intensity_image.shape\n",
    "    blank = np.ones((nq, nfiles), dtype=float)\n",
    "    qq = bg[:, 0]\n",
    "    bg_I = bg[:, 1]\n",
    "    index = np.arange(nfiles)\n",
    "    X1 = (qq.reshape(nq,1)*blank).flatten()\n",
    "    X2 = (index.reshape(1,nfiles)*blank).flatten()\n",
    "    X = np.array(zip(X1,X2))\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=tree_depth)\n",
    "    oldpredictions = []\n",
    "    for ii in range(max_iter):\n",
    "        smooth_diff = medfilt(diff_image, 3)\n",
    "        error_estimate = local_error_estimate(diff_image)\n",
    "        smooth_err = medfilt(error_estimate, 3)\n",
    "        frame4 = (np.fabs(smooth_diff) / cutoff > smooth_err)\n",
    "        frame5 = medfilt(frame4, 3)\n",
    "        frame6 = grow(frame5, 2)\n",
    "        Y = frame6.flatten()\n",
    "        clfsol = clf.fit(X, Y)\n",
    "        prediction = (clfsol.predict(X)).reshape(nq, nfiles)\n",
    "        metrics = []\n",
    "        for jj in oldpredictions:\n",
    "            metric = (jj != prediction).sum()\n",
    "            metrics.append(metric)\n",
    "        if ii != 0:\n",
    "            metricbest = min(metrics)\n",
    "            indexbest = metrics.index(metricbest)\n",
    "            if metricbest == 0:\n",
    "                if indexbest == (len(metrics) - 1):\n",
    "                    print \"Converged, iteration %i\" % ii\n",
    "                    suffix = \"\"\n",
    "                else:\n",
    "                    cyclelength = (len(metrics) - indexbest)\n",
    "                    print \"Cyclical convergence, iteration %i, cycle length %i\" % (ii, cyclelength)\n",
    "                    suffix = \", cycle length %i\" % cyclelength\n",
    "                    for kk in range(1, cyclelength):\n",
    "                        prediction = (prediction | oldpredictions[-kk])\n",
    "                        oldpredictions.append(prediction)\n",
    "                break\n",
    "        oldpredictions.append(prediction)\n",
    "        mult, diff_image = twodeebg(intensity_image, bg_I, ~prediction)\n",
    "    if demonstrative:\n",
    "        nplots = len(oldpredictions)\n",
    "        fig, ax = plotarray(nplots)\n",
    "        flatax = ax.ravel()\n",
    "        for ii in range(nplots):\n",
    "            axii = flatax[ii]\n",
    "            if ii < nplots:\n",
    "                axii.tick_params(axis='both', which='both', bottom='off', top='off', labelbottom='off', right='off', left='off',\n",
    "                                labelleft='off')\n",
    "                axii.imshow(oldpredictions[ii].T, cmap='binary')\n",
    "                if ii != (nplots-1):\n",
    "                    axii.set_title(ii)\n",
    "                else:\n",
    "                    axii.set_title(\"Final\")\n",
    "        fig.suptitle(\"Evolution of decision tree selection\" + suffix)\n",
    "        fig2, ax2 = plt.subplots()\n",
    "        ax2.imshow(diff_image.T,cmap='viridis')\n",
    "        ax2.axis('off')\n",
    "        ax2.set_title(\"Final background-subtracted spectra\")\n",
    "        if loc is not None:\n",
    "            fname = (loc + '_dtree_bgselection_evolution.pdf')\n",
    "            fig.savefig(fname)\n",
    "            fname2 = (loc + '_diffimage_final.pdf')\n",
    "            fig2.savefig(fname2)\n",
    "        #fig.set_figheight(8)\n",
    "        #fig.set_figwidth(12)\n",
    "        #return prediction, mult, diff_image, fig, fig2\n",
    "    return prediction, mult, diff_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map1, mult1, final_diff_image1 = tree_bg(intensity_image1, diff_image1, bg1, 1.5, 5, demonstrative=True, loc=loc1)\n",
    "feature_map2, mult2, final_diff_image2 = tree_bg(intensity_image2, diff_image2, bg2, 1.5, 5, demonstrative=True, loc=loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pseudovoigt_a(x, aG, aL, x0, sigma):\n",
    "    x_ = (x - x0)/sigma\n",
    "    return aG*np.exp(-0.5*(x_**2)) + aL*(1 + (x_**2))**-1\n",
    "\n",
    "def pseudovoigt_I(x, I, eta, x0, sigma):\n",
    "    x_ = (x - x0)/sigma\n",
    "    cG = (2*np.pi*sigma**2)**-0.5\n",
    "    cL = (np.pi*sigma)**-1\n",
    "    return I*eta*cG*np.exp(-0.5*(x_**2)) + I*(1-eta)*cL*(1 + (x_**2))**-1\n",
    "\n",
    "\n",
    "def PtSn1_bounds(nfiles):\n",
    "    \n",
    "    # a1, x1, deltax1, s1, a1factor, s1factor, a2, x2, deltax2, s2, a2factor, s2factor\n",
    "    bounds_lo = np.zeros((2*nfiles+10,), dtype=float)\n",
    "    bounds_hi = np.ones((2*nfiles+10,), dtype=float)*np.inf\n",
    "    #bounds_lo[0:nfiles] = #a1\n",
    "    bounds_lo[nfiles] = 2.69 #x1\n",
    "    bounds_lo[nfiles+1] = -0.002 #deltax1\n",
    "    bounds_lo[nfiles+2] = 0.025 #s1\n",
    "    bounds_lo[nfiles+3] = 0.05 #a1factor_0\n",
    "    bounds_lo[nfiles+4] = 0.5 #s1factor\n",
    "    #bounds_lo[nfiles+5:2*nfiles+5] = #a2\n",
    "    bounds_lo[2*nfiles+5] = 2.80 #x2\n",
    "    bounds_lo[2*nfiles+6] = -0.002 #deltax2\n",
    "    bounds_lo[2*nfiles+7] = 0.025 #s2\n",
    "    bounds_lo[2*nfiles+8] = 0.2 #a2factor_0\n",
    "    bounds_lo[2*nfiles+9] = 0.5 #s2factor_0\n",
    "    \n",
    "    bounds_hi[0:nfiles] = 12 #a1\n",
    "    bounds_hi[nfiles] = 2.79 #x1\n",
    "    bounds_hi[nfiles+1] = 0.002 #deltax1\n",
    "    bounds_hi[nfiles+2] = 0.08 #s1\n",
    "    bounds_hi[nfiles+3] = 1. #a1factor_0\n",
    "    bounds_hi[nfiles+4] = 2. #s1factor\n",
    "    bounds_hi[nfiles+5:2*nfiles+5] = 6.5 #a2\n",
    "    bounds_hi[2*nfiles+5] = 2.90 #x2\n",
    "    bounds_hi[2*nfiles+6] = 0.002 #deltax2\n",
    "    bounds_hi[2*nfiles+7] = 0.08 #s2\n",
    "    bounds_hi[2*nfiles+8] = 1. #a2factor_0\n",
    "    bounds_hi[2*nfiles+9] = 2. #s2factor_0\n",
    "    return [bounds_lo, bounds_hi]\n",
    "\n",
    "def gauss(x, a, x0, sigma):\n",
    "    #return (2*np.pi*sigma**2)**-0.5 * np.exp(-0.5*((x - x0)/sigma)**2)\n",
    "    return a * np.exp(-0.5*((x - x0)/sigma)**2)\n",
    "\n",
    "def multipeaks1(x, *params):\n",
    "    '''Group of peaks with constant amplitude ratios, constant location ratios, constant width ratios'''\n",
    "    # params pattern:  a0, x0, s0, a1factor, x1factor, s1factor, a2factor, x2factor, s2factor...\n",
    "    params = np.array(params)\n",
    "    npeaks = params.size/3\n",
    "    y = np.zeros(x.shape,dtype=float)\n",
    "    a0, x0, s0 = params[0:3]\n",
    "    for ii in range(npeaks):\n",
    "        afactori,xfactori,sfactori = params[3*ii:3*ii+3]\n",
    "        ai = afactori*a0\n",
    "        xi = xfactori*x0\n",
    "        si = sfactori*s0\n",
    "        y += gauss(x,ai,xi,si)\n",
    "    return y\n",
    "\n",
    "def pseudovoigt(x, aG, aL, x0, sigma):\n",
    "    x_ = (x - x0)/sigma\n",
    "    return aG*np.exp(-0.5*(x_**2)) + aL*(1 + (x_**2))**-1\n",
    "\n",
    "def interpret(opt):\n",
    "    aG, aL, x0, sigma = opt\n",
    "    h = aG + aL\n",
    "    I = aG*sigma*(2*np.pi)**0.5 + aL*np.pi*sigma\n",
    "    #return h, I, x0, sigma\n",
    "    return I, x0, sigma\n",
    "\n",
    "\n",
    "def multipeaks2(x, *params):\n",
    "    '''Group of pseudovoigt peaks with constant integrated intesity ratios, constant location ratios, constant width ratios'''\n",
    "    # params pattern:  a0, x0, s0, a1factor, x1factor, s1factor, a2factor, x2factor, s2factor...\n",
    "    params = np.array(params)\n",
    "    npeaks = params.size/3\n",
    "    y = np.zeros(x.shape,dtype=float)\n",
    "    a0, x0, s0 = params[0:3]\n",
    "    for ii in range(npeaks):\n",
    "        afactori,xfactori,sfactori = params[3*ii:3*ii+3]\n",
    "        ai = afactori*a0\n",
    "        xi = xfactori*x0\n",
    "        si = sfactori*s0\n",
    "        y += gauss(x,ai,xi,si)\n",
    "    return y\n",
    "\n",
    "def linear2(ii, b, a):\n",
    "    return ii*a + b\n",
    "\n",
    "def Pt_phase1(qq, a1, x1, s1, afactor, sfactor):\n",
    "    return multipeaks(qq, a1, x1, s1, afactor, (4./3)**0.5, sfactor)\n",
    "\n",
    "def PtSn_q2q3(qq, a1, x1, s1, afactor, sfactor):\n",
    "    return multipeaks(qq, a1, x1, s1, afactor, 0.9495**-1, sfactor)\n",
    "\n",
    "def PtSn1_full(X, *params):\n",
    "    # a1, x1, deltax1, s1, a1factor, s1factor, a2, x2, deltax2, s2, a2factor, s2factor\n",
    "    #nq, nfiles = diff_image.shape\n",
    "    qq, ii = X\n",
    "    params = np.array(params)\n",
    "    nfiles = (params.size - 10)/2\n",
    "    nq = qq.size/nfiles\n",
    "    a1 = params[:nfiles]\n",
    "    x1 = params[nfiles]\n",
    "    deltax1 = params[nfiles+1]\n",
    "    s1 = params[nfiles+2]\n",
    "    a1factor = params[nfiles+3]\n",
    "    s1factor = params[nfiles+4]\n",
    "    a2 = params[nfiles+5:2*nfiles+5]\n",
    "    x2 = params[nfiles+5]\n",
    "    deltax2 = params[nfiles+6]\n",
    "    s2 = params[nfiles+7]\n",
    "    a2factor_0 = params[nfiles+8]\n",
    "    s2factor_0 = params[nfiles+9]\n",
    "    A1 = (a1[np.newaxis,:]*np.ones((nq,nfiles),dtype=float)).flatten()\n",
    "    X1 = linear2(ii, x1, deltax1)\n",
    "    S1 = s1*np.ones(X1.shape)\n",
    "    A2 = (a2[np.newaxis,:]*np.ones((nq,nfiles),dtype=float)).flatten()\n",
    "    X2 = linear2(ii, x2, deltax2)\n",
    "    S2 = s2*np.ones(X2.shape)\n",
    "    return Pt_phase1(qq, A1, X1, S1, a1factor, s1factor) + PtSn_q2q3(qq, A2, X2, S2, a2factor_0, s2factor_0)\n",
    "\n",
    "def duo_guess(iis, a1s, x1s, s1s, a2s, x2s, s2s):\n",
    "    (x1, x1slope), _ = curve_fit(linear2, iis, x1s, p0=[x1s.mean(), 0])\n",
    "    s1 = s1s.mean()\n",
    "    s1factor = s2s.mean()/s1\n",
    "    a1factor = a2s.mean()/a1s.mean()\n",
    "    x1factor = x2s.mean()/x1\n",
    "    a1 = (a1s + a2s)/(1 + a1factor)\n",
    "    return a1, x1, x1slope, s1, a1factor, x1factor, s1factor\n",
    "\n",
    "def guess_from_outputs(outputs):\n",
    "    nfeatures, nfiles = outputs.shape\n",
    "    # unpacking outputs\n",
    "    a1_0 = outputs[0,:]\n",
    "    x1_0 = outputs[1,:]\n",
    "    s1_0 = outputs[2,:]\n",
    "    a2_0 = outputs[3,:]\n",
    "    x2_0 = outputs[4,:]\n",
    "    s2_0 = outputs[5,:]\n",
    "    a3_0 = outputs[6,:]\n",
    "    x3_0 = outputs[7,:]\n",
    "    s3_0 = outputs[8,:]\n",
    "    a4_0 = outputs[9,:]\n",
    "    x4_0 = outputs[10,:]\n",
    "    s4_0 = outputs[11,:]\n",
    "    ii_0 = np.arange(a1_0.size, dtype=float)\n",
    "    # initial param guesses\n",
    "    # a1, x1, s1, a2, x2, s2, a3, x3, s3, a4, x4, s4 in outputs\n",
    "    # vs\n",
    "    # a1, x1, s1, a1factor, x1factor, a2, x2, s2, a2factor, x2 factor for full fit\n",
    "    a1, x1, deltax1, s1, a1factor_0, x1factor_0, s1factor_0 = duo_guess(ii_0, a1_0, x1_0, s1_0, a4_0, x4_0, s4_0)\n",
    "    a2, x2, deltax2, s2, a2factor_0, x2factor_0, s2factor_0 = duo_guess(ii_0, a2_0, x2_0, s2_0, a3_0, x3_0, s3_0)\n",
    "    a_conglomerate = np.zeros((2*nfiles,))\n",
    "    a_conglomerate[:nfiles] = a1_0\n",
    "    a_conglomerate[nfiles:] = a2_0\n",
    "    guesses = [a1_0, x1, deltax1, s1, a1factor_0, x1factor_0, s1factor_0]\n",
    "    guesses.extend([a2_0, x2, deltax2, s2, a2factor_0, x2factor_0, s2factor_0])\n",
    "    #return a1, x1, deltax1, s1, a1factor, s1factor, a2, x2, deltax2, s2, a2factor, s2factor\n",
    "    print \"guesses size\", len(guesses), \"should be 14\"\n",
    "    return guesses\n",
    "\n",
    "\n",
    "def pack_list_of_lists_to_array(lol):\n",
    "    '''Converts [[a,b],[c],d] to array([a,b,c,d]).'''\n",
    "    n_elements = 0\n",
    "    for ii in range(len(lol)):\n",
    "        try: # type(lol[ii]) in [list, np.ndarray, tuple]\n",
    "            n_elements += len(lol[ii])\n",
    "        except TypeError:\n",
    "            n_elements += 1\n",
    "    lolarray = np.zeros((n_elements,),dtype=float)\n",
    "    element = 0\n",
    "    for ii in range(len(lol)):\n",
    "        try: # type(lol[ii]) in [list, np.ndarray, tuple]\n",
    "            lolarray[element:element+len(lol[ii])] = lol[ii]\n",
    "            element += len(lol[ii])\n",
    "        except TypeError:\n",
    "            lolarray[element] = lol[ii]\n",
    "            element += 1\n",
    "    return lolarray\n",
    "\n",
    "def PtSn1paramfromguess(guess):\n",
    "    a1, x1, deltax1, s1, a1factor_0, x1factor_0, s1factor_0 = guess[:7]\n",
    "    a2, x2, deltax2, s2, a2factor_0, x2factor_0, s2factor_0 = guess[7:]\n",
    "    print \"x1factor guess is %f; expected %f\" % (x1factor_0, (4./3)**0.5)\n",
    "    print \"x2factor guess is %f; expected %f\" % (x2factor_0, 0.9495**-1)\n",
    "    guess.pop(13)\n",
    "    guess.pop(6)\n",
    "    params = pack_list_of_lists_to_array(guess)\n",
    "    return params\n",
    "\n",
    "def inbounds(p0, bounds):\n",
    "    for ii in range(len(p0)):\n",
    "        if p0[ii] < bounds[0][ii]:\n",
    "            p0[ii] = bounds[0][ii]\n",
    "            print \"Parameter at index %i was raised because out of bounds\" %ii\n",
    "        if p0[ii] > bounds[1][ii]:\n",
    "            p0[ii] = bounds[1][ii]\n",
    "            print \"Parameter at index %i was lowered because out of bounds\" %ii\n",
    "        if bounds[0][ii] > bounds[1][ii]:\n",
    "            raise ValueError(\"Lower bound must be <= upper bound.  Exception at index %i\"%ii)\n",
    "    return p0\n",
    "\n",
    "def fit_collective(diff_image, bg, outputs, funcname, nofit, demonstrative=False):\n",
    "    diff_image = diff_image[:,~nofit]\n",
    "    outputs = outputs[:,~nofit]\n",
    "    nq, nfiles = diff_image.shape\n",
    "    blank = np.ones((nq, nfiles), dtype=float)\n",
    "    qq,_,_,_ = bg.T\n",
    "    #qq,bg_I,_,_ = bg.T\n",
    "    index = np.arange(nfiles)\n",
    "    qq_big = qq.reshape(nq,1)*blank\n",
    "    X1 = qq_big.flatten()\n",
    "    index_big = index.reshape(1,nfiles)*blank\n",
    "    X2 = index_big.flatten()\n",
    "    X = np.array((X1,X2))\n",
    "    Y = diff_image.flatten()\n",
    "    #a1, deltaa1, x1, deltax1, s1, deltas1, a1factor, x1factor, a2, deltaa2, x2, deltax2, s2, deltas2, a2factor, x2factor = guess_from_outputs(outputs)\n",
    "    #a1, x1, deltax1, s1, deltas1, a1factor, x1factor, a2, x2, deltax2, s2, deltas2, a2factor, x2factor = guess_from_outputs(outputs)\n",
    "    if funcname == 'PtSn1_full':\n",
    "        # X, a1, x1, deltax1, s1, deltas1, a1factor, _, a2, x2, deltax2, s2, deltas2, a2factor, _\n",
    "        # only a1 and a2 are arrays size 180\n",
    "        p0 = PtSn1paramfromguess(guess_from_outputs(outputs))\n",
    "        bounds = PtSn1_bounds(nfiles)\n",
    "        p0 = inbounds(p0,bounds)\n",
    "        popt, pcov = curve_fit(PtSn1_full, X, Y, p0=p0, bounds=bounds)\n",
    "        fit_result = PtSn1_full(X, *popt).reshape(nq,nfiles)\n",
    "    elif funcname == 'PtSn2_full':\n",
    "        # X, a1, x1, deltax1, s1, deltas1, a1factor, _, a2, x2, deltax2, s2, deltas2, a2factor, _\n",
    "        # only a1 and a2 are arrays size 180\n",
    "        p0 = PtSn2paramfromguess(guess_from_outputs(outputs))\n",
    "        p0 = inbounds(p0,bounds)\n",
    "        popt, pcov = curve_fit(PtSn2_full, X, Y, p0=p0)\n",
    "        fit_result = PtSn2_full(X, *popt).reshape(nq,nfiles)\n",
    "    else:\n",
    "        raise ValueError(\"Function name not recognized.\")\n",
    "    if demonstrative:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(fit_result.T)\n",
    "    return popt, pcov, fit_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "popt1, pcov1, fit_result1 = fit_collective(final_diff_image1, bg1, outputs1, 'PtSn1_full', nofit1, True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "popt2, pcov2, fit_result2 = fit_collective(final_diff_image2, bg2, outputs2, 'PtSn2_full', nofit2, True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print len(files1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pack_list_of_lists_to_array(lol):\n",
    "    '''Converts [[a,b],[c],d] to array([a,b,c,d]).\n",
    "    \n",
    "    Sequence (array, list, tuple) and singleton (number) list elements allowed.\n",
    "    \n",
    "    Array elements are expected to come pre-flattened.  Result is assumed to be float type.\n",
    "    '''\n",
    "    n_elements = 0\n",
    "    for ii in range(len(lol)):\n",
    "        try: # type(lol[ii]) in [list, np.ndarray, tuple]\n",
    "            n_elements += len(lol[ii])\n",
    "        except TypeError:\n",
    "            n_elements += 1\n",
    "    lolarray = np.zeros((n_elements,),dtype=float)\n",
    "    element = 0\n",
    "    for ii in range(len(lol)):\n",
    "        try: # type(lol[ii]) in [list, np.ndarray, tuple]\n",
    "            lolarray[element:element+len(lol[ii])] = lol[ii]\n",
    "            element += len(lol[ii])\n",
    "        except TypeError:\n",
    "            lolarray[element] = lol[ii]\n",
    "            element += 1\n",
    "    return lolarray\n",
    "\n",
    "def pattern_unpack(pattern, packarray):\n",
    "    '''Inverts the work of pack_list_of_lists_to_array.'''\n",
    "    unpacked = []\n",
    "    element = 0\n",
    "    n_elements = packarray.size\n",
    "    for ii in range(len(pattern)):\n",
    "        try:\n",
    "            unpacked.append(packarray[element:element+len(pattern[ii])])\n",
    "            element += len(pattern[ii])\n",
    "        except TypeError:\n",
    "            unpacked.append(packarray[element])\n",
    "            element += 1\n",
    "        except IndexError:\n",
    "            print \"The pattern seems to have more elements than the array to be unpacked.\"\n",
    "    if element < (n_elements-1):\n",
    "        raise IndexError(\"The pattern seems to have fewer elements than the array to be unpacked.\")\n",
    "    return unpacked\n",
    "    \n",
    "\n",
    "print pack_list_of_lists_to_array([[1,2],[3],4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Pt_lowconstraint(qq, a1, x1, s1, a2, s2):\n",
    "    return manypeaks(qq, a1, x1, s1, a2, x1*(4./3)**0.5, s2)\n",
    "\n",
    "def PtSn_lowconstraint(qq, a1, x1, s1, a2, s2):\n",
    "    return manypeaks(qq, a1, x1, s1, a2, x1*0.9495**-1, s2)\n",
    "\n",
    "def hybrid_Pt_PtSn_lowconstraint(qq, *pars):\n",
    "    pars1 = list(pars)[:5]\n",
    "    pars2 = list(pars)[5:]\n",
    "    return Pt_lowconstraint(qq, *pars1) + Pt_lowconstraint(qq, *pars2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
